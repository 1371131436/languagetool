<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
<HEAD>
<TITLE></TITLE>
</HEAD>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1250">
<META NAME="KEYWORDS" 
CONTENT="Spellcheck Helyesírásellenõrzõ Rechtschreibprüfer Wörterbuch dictionary Szótár">
<BODY bgcolor = "#fff8f8">
<div align="center"><center>
<table border="0" cellpadding="0" cellspacing="0" width="85%" cols="1">
<tr><td bgcolor="#fff8f8" width="4">&nbsp;</td><td>&nbsp;&nbsp;&nbsp;</td><td>
<FONT SIZE="+1">
<h2>Daniel Naber's language tool for other languages than English.</h2>
<P>

(http://www.danielnaber.de)
<P>

Contents:
<BR>
<a href=#r01>What had to be changed</a>
<BR>
&nbsp;&nbsp;&nbsp;<a href=#r02>Code changes in Tagger.py:</a>
<BR>
&nbsp;&nbsp;&nbsp;<a href=#r02a>Code changes in Rules.py:</a>
<BR>
&nbsp;&nbsp;&nbsp;<a href=#r02b>The Wfinder.py module:</a>
<BR>
&nbsp;&nbsp;&nbsp;<a href=#r03>Modification in TextChecker.py</a>
<BR>
<a href=#r03a>Language discrimination:</a>
<BR>
<a href=#r04>Still to be done:</a>
<BR>
<a href=#r05>Timing consideration:</a>
<BR>
<a href=#r06>Adding new languages</a>
<BR>
<a href=#r07>How to use</a>
<P>

-------------------------------------------------------------
<BR>
<A name=r01></A>
<BR>
<h3>To handle other languages than English (here: German and Hungarian) the following changes needed to be done:</h3>
<P>

<li> Set up the word types that cover that language's peculiarities. Here it is important, that you look into the target language's  typical errors and formalistic rules. The description of the German word types is stored in the file TagInfo.py</li>
<P>

<li>  In German, for example for each verb the personal pronom has to be given, and the both must match. For example, ich gehe is OK, ich gehst is not OK, etc...</li>
<P>

<li>   In German also the ending of the adjectives must follow the grammatical sex of the nomen. For example, das schöne Haus is OK, das schönem Haus is not OK, der gute alter Mann is not OK, etc...</li>
<P>

<li>   Since in German the words' grammatical sex is so important, the dictionary (see next item) must be declared as a word type and  must be stored in the dictionary.</li>
<P>

<li>  Prepare a rule set in the rules path, called yourlanguagegrammar.xml, e.g degrammar.xml, that handles the tipical errors in the target language. This is the soul of the language checking, and the rules must be written and tested very carefully. Be careful, if you use non-ascii characters, python unfortunately is quite strange in this.</li>
<BR>
<A name=r11></A>
<BR>
<li>  Prepare a dictionary of the given language that contains for each word the following information:</li>
<P>

   word/affixes/word type1/probability1/wordtype2/probability2/...
<BR>
   where affixes are the affixes the myspell dictionary uses.
<P>

   For example for German:
<BR>
   Abendgymnasium/Sr/NNS/1
<BR>
   Abendhauch/EPST/NMS/1
<P>

 <b>  To collect the dictionary is clearly the hardest part of the job!!</b>
<P>

<li>  Luckily only the modules <i>Tagger.py</i> and slightly <i>Rules.py, TextChecker.py</i> and <i>TagInfo.py</i> had to be modified in order to make the the language tool a multi language one, and a word  finder and tag preparing module, <i>Wfinder.py</i> had to be added.</li>
<P>

<A name=r02></A>
<BR>
<h3>  Code changes in Tagger.py:</h3>
<P>

  Tagger.py must import Wfinder and at the very beginning create an  object, wfinder, that reads the dictionary file described above and the affix file, which is identical to the affix file, the myspell program uses. The files are in the path data, deutsch.aff and deutsch.txt.
<P>

  Tagger.py got some global variables, the language, the aff file name and the dict file name, since these variables are only interesting for Tagger.py and Wfinder.py.
<P>

  The methods bindData must use the ReadData method to read in the  data. I am still evaluating, if this read-in can be eliminated  altogether, since now Wfinder.py handles the dictionaries. Since there is some logic to handle tag probabilities in Tagger.py, the ReadData is still needed. BindData also does not try to read the additional tag probality files any more.
<P>

  DeleteData gets an empty method, since the program does not learn while checking the text any more, and also does not modify the dictionary any more.
<P>

  CommitData does not pickle any more the structures onto files, just prints some informations.
<P>

  ReadData reads the dictionary from a file. This could be eliminated in a next version as written at bindData.
<P>

  guessTags has to be modified, and the rules, that apply only to English Texts, must be if-ed using if text1language == 'English':.
<P>

  Also in the tag function some English only logic had to be if-ed out. In the tag function I also had to add several lines:
<P>

if len(word) >= 1 and word[-1] == '.':
<BR>
&nbsp;&nbsp;word = word[0:-1]
<BR>
&nbsp;&nbsp;r = Text.tagWord(self, word, data_table)
<BR>
&nbsp;&nbsp;tagged_list.extend(r)
<BR>
&nbsp;&nbsp;word = '.'
<BR>
r = Text.tagWord(self, word, data_table)
<BR>
tagged_list.extend(r)
<P>

To cut the trailing dot. Otherwise valid words were not found because of the trailing dot. This is probably due to cutting of several English only functionality .
<P>


<A name=r02b></A>
<BR>
<h3> The Wfinder.py module:</h3>
<P>


  The main modification is in the TagWord method. Rather than using data_table.has_key(word) in order to find the word, it uses for non-English texts rc = wfinder.test_it(word) to find the word. Test_it is located in <i>Wfinder.py</i>. It checks the  dictionary, using the Dömölki-algorithm, also myspell uses,  if this word is to be found. This must be done like that, because words in agglutinating languages having 1000-2000 variations of each word cannot be handled by simple hash table searches like the has_key method. But using affixes reduces also the size of an English word collection by 2, and a German one by 6.
<P>

  Test_it also contains a language specific tag refinement addition. If in German a verb is found, test_it finds out according to the verb's ending, which person uses the verb (me, you, he, we, they, etc..) and refines the tag V to V11...V15. It also checks for adjectives' ending and refines the ADJ tag to ADJE...ADJEM.
<P>

  In Wfinder.py several encode('iso-8859-1') and unicode(string,'iso-8859-1') had to be added, otherwise the lowercase umlauts and other non ascii characters are not converted to lowercase, when the word is in uppercase as the first word of a sentence. If a target language is a non iso-8859-1 characterset language, this coding has to be changed accordingly. This is not trivial to do in python, that (unfortunately) supports ascii primarily since version 1.5.
<P>

<A name=r02a></A>
<BR>
<h3>  Code changes in Rules.py:</h3>
<P>

  The file names and class names  under python_rules path were modified. AvsAnRule is renamed to enAvsAnRule, since this applies only for English texts. allWordRepeat also applies to German and Hungarian, even though repeated word might be correct in German or Hungarian. It should be useful for every language. The allSentenceLength rule is pretty general for any language on the world. In <i>Rules.py</i> for each language will be now checked, if the rule applies for the active language or if it applies for all languages. Otherwise the rule will not be applied to the checked text. For English, the applied rule files and the classes must have 'en' or 'all' as the first characters, while for German 'de' or 'all'.
<P>


<A name=r03></A>
<BR>
<h3>Modification in TextChecker.py</h3>
<P>

The language is set in TextChecker, the variable text1language, that is a global variable in Tagger. TextChecker reads the TextChecker.ini file, which is in the same directory, where TextChecker is, and sets up the right file names for the aff and dictionary file in the data path and the grammar file in the rules path.
<P>

I have also documented the German word types in TagInfo.py.
<P>

<A name=r03a></A>
<BR>
<h3>Language discrimination:</h3>
<P>

  The language identification is done using the -x flag followed by  the language identification, which is English for English texts, German for German ones and Hungarian for Hungarian ones. TextChecker uses an initialization file, TextChecker.ini, which is in the same directory as TextChecker.py. It contains a section for each supported language. It looks now:
<P>

[German]
<BR>
dicFile=deutsch.txt
<BR>
affFile=deutsch.aff
<BR>
grammarFile=degrammar.xml
<P>

[English]
<BR>
dicFile=words
<BR>
affFile=english.aff
<BR>
grammarFile=engrammar.xml
<P>

[Hungarian]
<BR>
dicFile=hungarian.txt
<BR>
affFile=hungarian.aff
<BR>
grammarFile=hugrammar.xml
<P>

The file names are used in Tagger.py or Rules.py.
<P>

<A name=r04></A>
<BR>
<h3>Still to be done:</h3>
<P>

  There are several technically unnecessary or incorrect files for other languages than English, used in the data directory: det_an.txt, det_a.txt, c7toc5.txt, abbr.txt, chunks.txt.
<P>

  Chunk handling is not yet implemented for German or Hungarian, since strictly  seen it is not necessary, but a nice feature.
<P>

In German the grammatical sex of a word is determined by the last word in case of compound words. It would probably make sense, to build such a determination into Wfinder.py, and then all German words were covered by the dictionary. The disadvantages of this approach are, however, thet the last word's determination cannot be done absolutely error free, and also, that this check would be quite time consuming.
<P>

The groups adj, int and ind are not very well sorted in German, e.g. these word types are intermixed. Since the present rules don't use them, this is now no problem, but the dictionary should be tidied up later.
<P>

TagInfo.py needs to be enhanced to be able to show the tag information for any language. (At present it only shows the English tag information).
<P>

<A name=r05></A>
<BR>
<h3>Timing consideration:</h3>
<P>

  The dictionary read-in takes about 20-30 seconds. This is due to  the large size of the dictionaries, and cannot be reduced. The program timing is otherwise unchanged.
<P>

<A name=r06></A>
<BR>
<h3>Adding new languages</h3>
<P>

If you want to add a new language, the following actions are needed:
<P>

<li>Check and understand the grammar rules of the target language. Check existing texts agains typical errors, and try to set up rules for them. Read the original English, German and Hungarian rules, and check, if these are applyable for the target language. Especially in the English rules there are lots of useful tips.</li>
<P>

<li>If the rules are ready, you also have the word types of the target language with them. Now get a word list for myspell, and add the word types to that list. Check the German word list, how this must be done. See the short example <a href=#r11>above</a> </li>
<P>

<li>Set up a small word list that contains all the word types, your rules handle. Check the rules using this small word list and modify the word types and/or make refinements, if necessary </li>
<P>

<li>If the word types need to be identified on the fly (which is very likely), enter your rules into the module Wfinder.py into the marked part:
<BR>
#
<BR>
# Here are the language specific rules of each language
<BR>
#
<BR>
			else if Tagger.text1language == 'YourLanguage':
<BR>
......................--insert your rules here
<BR>
# end of language specific rules for new languages.
<BR>
#</li>
<P>

<li> Test your rules using TextChecker.py, refine and enrich them step by step.</li>
<P>

<li> Document your word types in the file TagInfo.py.</li>
<P>

<A name=r07></A>
<BR>
<h3>How to use</h3>
<P>

  Simply unzip the languagetool file somewhere in your system. Go with a command window into the upper path (where the most python files are stored like TextChecker.py), and enter:
<P>

 <i> python TextChecker.py -x German tests/detest1.txt.</i>
<BR>
 or
<BR>
 <i> python TextChecker.py -x Hungarian tests/hutest1.txt.</i>
<BR>
 or
<BR>
 <i> python TextChecker.py -x English tests/entest7.txt.</i>
<P>

This implies, that you must have a python interpreter installed and you must have a path to the executable python command. After a short time (0.5-2 minutes) a bunch of xml coded error messages will appear on your screen.
<P>

The output of the sample test files (entest.txt..entest7.txt and detest1.txt, detest2.txt, hutest1.txt, hutest2.txt) is stored in entest.out, detest.out and hutest.out in the test directory. If you make changes, please check, if the output of these tests remained the same.
<P>

Regards tr, transam45@nospam.gmx.net
<BR>
Please remove the nospam, if you wish to email to me.
<BR>
http://tkltrans.sf.net
<P>

</td>   </tr>
 </table></center></div>
</BODY>
</HTML>
